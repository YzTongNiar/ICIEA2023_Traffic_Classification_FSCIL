{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def build_trainset(encoding_data, args):\n",
    "    '''\n",
    "        divide training set into different tasks\n",
    "    '''\n",
    "    scenario_train = []\n",
    "    for task_id in range(args.num_tasks):\n",
    "        task = []\n",
    "        if task_id == 0:\n",
    "            for sample in encoding_data:\n",
    "                if sample[1] <= args.num_bases - 1:\n",
    "                    task.append(sample)\n",
    "            scenario_train.append(task)\n",
    "        else:\n",
    "            for sample in encoding_data:\n",
    "                if args.num_bases + (task_id - 1) * args.increment - 1 < sample[\n",
    "                    1] <= args.num_bases + task_id * args.increment - 1:\n",
    "                    task.append(sample)\n",
    "            scenario_train.append(task)\n",
    "    return scenario_train\n",
    "\n",
    "\n",
    "class Arguments:\n",
    "    def __init__(self, num_bases, increment, num_tasks):\n",
    "        self.num_bases = num_bases\n",
    "        self.increment = increment\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "\n",
    "args = Arguments(5, 3, 6)\n",
    "save_path1 = 'encoded__train_data.pkl'  # Encoded data pkl file\n",
    "with open(save_path1, 'rb') as ff:\n",
    "    train_data = pickle.load(ff)\n",
    "    ff.close()\n",
    "scenario_train = build_trainset(train_data, args)\n",
    "train_seq = scenario_train[0]\n",
    "\n",
    "\n",
    "def nem_add(\n",
    "        task_id,\n",
    "        features: np.ndarray,\n",
    "        base_mem_size,\n",
    "        inc_mem_size\n",
    "):\n",
    "    if len(features.shape) != 2:\n",
    "        raise ValueError(f\"Expected features to have 2 dimensions, not {len(features.shape)}d.\")\n",
    "\n",
    "    indexes = []\n",
    "\n",
    "    if task_id == 0:\n",
    "        num_classes = 5\n",
    "        num_samples = 90\n",
    "        num_per_class = base_mem_size\n",
    "    else:\n",
    "        num_classes = 3\n",
    "        num_samples = 10\n",
    "        num_per_class = inc_mem_size\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        class_indexes = np.array(range(class_id * num_samples, (class_id + 1) * num_samples))\n",
    "        class_features = features[class_indexes]\n",
    "\n",
    "        D = class_features.T\n",
    "        D = D / (np.linalg.norm(D, axis=0) + 1e-8)\n",
    "        mu = np.mean(D, axis=1)\n",
    "        herding_matrix = np.zeros((class_features.shape[0],))\n",
    "\n",
    "        w_t = mu\n",
    "        iter_herding, iter_herding_eff = 0, 0\n",
    "\n",
    "        while not (\n",
    "                np.sum(herding_matrix != 0) == min(num_per_class, class_features.shape[0])\n",
    "        ) and iter_herding_eff < 1000:\n",
    "            tmp_t = np.dot(w_t, D)\n",
    "            ind_max = np.argmax(tmp_t)\n",
    "            iter_herding_eff += 1\n",
    "            if herding_matrix[ind_max] == 0:\n",
    "                herding_matrix[ind_max] = 1 + iter_herding\n",
    "                iter_herding += 1\n",
    "\n",
    "            w_t = w_t + mu - D[:, ind_max]\n",
    "\n",
    "        herding_matrix[np.where(herding_matrix == 0)[0]] = 10000\n",
    "\n",
    "        tmp_indexes = herding_matrix.argsort()[:num_per_class]\n",
    "        indexes.append(class_indexes[tmp_indexes])\n",
    "\n",
    "    indexes = np.concatenate(indexes)\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def random_add(task_id, base_mem_size, inc_mem_size):\n",
    "    select_id = []\n",
    "    if task_id == 0:\n",
    "        num_classes = 5\n",
    "        num_samples = 90\n",
    "        num_per_class = base_mem_size\n",
    "    else:\n",
    "        num_classes = 3\n",
    "        num_samples = 10\n",
    "        num_per_class = inc_mem_size\n",
    "    for class_id in range(num_classes):\n",
    "        sample_id = list(range(class_id * num_samples, (class_id + 1) * num_samples))\n",
    "        select_id = \\\n",
    "        np.concatenate((select_id, np.random.choice(sample_id, num_per_class)), axis=0)\n",
    "    return select_id\n",
    "\n",
    "\n",
    "def n2c_add(task_id, features: np.ndarray, base_mem_size, inc_mem_size):\n",
    "    indexes = []\n",
    "    if task_id == 0:\n",
    "        num_classes = 5\n",
    "        num_samples = 90\n",
    "        num_per_class = base_mem_size\n",
    "    else:\n",
    "        num_classes = 3\n",
    "        num_samples = 10\n",
    "        num_per_class = inc_mem_size\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        class_indexes = np.array(range(class_id * num_samples, (class_id + 1) * num_samples))\n",
    "        class_features = features[class_indexes]\n",
    "        class_mean = np.mean(class_features, axis=0, keepdims=True)\n",
    "\n",
    "        dist_to_mean = np.linalg.norm(class_mean - class_features, axis=1)\n",
    "        tmp_indexes = dist_to_mean.argsort()[:num_per_class]\n",
    "\n",
    "        indexes.append(class_indexes[tmp_indexes])\n",
    "\n",
    "    indexes = np.concatenate(indexes)\n",
    "    return indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "features = np.load('features.npy')\n",
    "selected_id_nem = nem_add(0, features, 10, 5)\n",
    "selected_id_n2c = n2c_add(0, features, 10, 5)\n",
    "selected_id_rand = random_add(0, 10, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def save_as_txt(test_results, train_results, save_path):\n",
    "    file = open(save_path,'w')\n",
    "    file.write('Test Results\\n')\n",
    "    for result in test_results:\n",
    "        file.write(str(result) + '\\n')\n",
    "    file.write('Train Results\\n')\n",
    "    for result in train_results:\n",
    "        file.write(str(result) + '\\n')\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "b = [[1,2,3],[1,2,3],[1,2,3]]\n",
    "a = [[1,2,3],[1,2,3],[1,2,3]]\n",
    "save_as_txt(a,b,'./Results/test.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}